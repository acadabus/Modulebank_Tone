{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pck\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import *\n",
    "from dateutil.parser import parse\n",
    "from multiprocessing import Pool\n",
    "from multiprocessing.dummy import Pool as DPool\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from openpyxl.styles import PatternFill, Border, Side, Alignment, Protection, Font\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import swifter\n",
    "import matplotlib as mpl\n",
    "import matplotlib.backends.backend_pdf\n",
    "import re\n",
    "from numba import jit\n",
    "import pymorphy2\n",
    "import math\n",
    "import gensim\n",
    "from typing import List, Tuple\n",
    "import openpyxl\n",
    "from googletrans import Translator\n",
    "import time\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "import plotly.express as px\n",
    "from datetime import *\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import plotly.io as pi\n",
    "\n",
    "pio.orca.config.use_xvfb = True\n",
    "pio.orca.config.use_xvfb = False\n",
    "mpl.rc(\"savefig\", dpi=200)\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "translator = Translator()\n",
    "\n",
    "pd.options.display.max_columns = 500\n",
    "pd.options.display.max_rows = 300\n",
    "\n",
    "import xlsxwriter\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_norm_dict = {}\n",
    "\n",
    "tmp_vector = np.array([0] * 300, dtype=np.float32)\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('../hh_data/model.bin', binary=True)\n",
    "def _word2vec(word):\n",
    "    for i in [\"_NOUN\", \"_ADJ\", \"_VERB\"]:\n",
    "        tmp = \"{}{}\".format(word, i)\n",
    "        if tmp in model:\n",
    "            return model[tmp]\n",
    "\n",
    "    return np.array(tmp_vector)\n",
    "\n",
    "def clean_text(name):\n",
    "    '''Первичная очистка названия вакансии'''\n",
    "    \n",
    "    # Приведем к нижнему регистру\n",
    "    name = name.lower()\n",
    "    \n",
    "    # Оставим только буквы\n",
    "    name = re.sub(r\"[^a-zа-я]+\", ' ', name).strip()\n",
    "    \n",
    "    return name\n",
    "\n",
    "def normalize_text(name):\n",
    "    \n",
    "    normal_name = \"\"\n",
    "    name = name.replace(\"\\n\", \" \")\n",
    "    # Для каждого слова в вакансии\n",
    "    for word in name.split():\n",
    "        \n",
    "        found_norm_word = None\n",
    "        \n",
    "        # Если слово не в кэше\n",
    "        if word not in words_norm_dict.keys():\n",
    "            # Распарсим его\n",
    "            norm_words = morph.parse(word)\n",
    "            \n",
    "            for norm_word in norm_words:\n",
    "                # Если слово не предлог и не союз\n",
    "                # Не в стоп словах и длинна слова больше одного символа\n",
    "                if word == 'не' or norm_word.tag.POS not in ['PREP', 'CONJ', 'PRCL', 'INTJ'] \\\n",
    "                    and norm_word.normal_form and len(norm_word.normal_form) > 1 and norm_word.score > 0.1 \\\n",
    "                    and np.linalg.norm(_word2vec(norm_word.normal_form)) > 0:\n",
    "                    \n",
    "                    # Сохраним первую форму слова\n",
    "                    found_norm_word = norm_word.normal_form\n",
    "                    break\n",
    "                    \n",
    "            # Запишем слово в кэш\n",
    "            words_norm_dict[word] = found_norm_word\n",
    "        else:\n",
    "            # Если слово находится в кэше - просто достанем результат\n",
    "            found_norm_word = words_norm_dict[word]\n",
    "\n",
    "        # Если результат не отрицательный и слово есть\n",
    "        if found_norm_word:\n",
    "            # Запишим его в нормализованную вакнасию\n",
    "            normal_name = f\"{normal_name} {found_norm_word}\"\n",
    "            \n",
    "    normal_name = normal_name.strip()\n",
    "    return normal_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Источник</th>\n",
       "      <th>Ссылка на источник</th>\n",
       "      <th>Ссылка на пост</th>\n",
       "      <th>Текст поста</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fb</td>\n",
       "      <td>https://www.facebook.com/bablorub</td>\n",
       "      <td>https://www.facebook.com/bablorub/posts/368965...</td>\n",
       "      <td>Как выживает ресторанная индустрия.\\nДа никак....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fb</td>\n",
       "      <td>https://www.facebook.com/bablorub</td>\n",
       "      <td>https://www.facebook.com/bablorub/posts/361902...</td>\n",
       "      <td>Ивентер 2019: ты едешь на велосипеде, который ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fb</td>\n",
       "      <td>https://www.facebook.com/bablorub</td>\n",
       "      <td>https://www.facebook.com/bablorub/posts/350016...</td>\n",
       "      <td>Что хорошего.\\r\\nАгентство май закончило с при...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fb</td>\n",
       "      <td>https://www.facebook.com/bablorub</td>\n",
       "      <td>https://www.facebook.com/bablorub/posts/349914...</td>\n",
       "      <td>Это просто огнище! Бизнес пинками загоняют в с...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fb</td>\n",
       "      <td>https://www.facebook.com/bablorub</td>\n",
       "      <td>https://www.facebook.com/bablorub/posts/360052...</td>\n",
       "      <td>Отложенный спрос работал только пару недель по...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Источник                 Ссылка на источник  \\\n",
       "0       fb  https://www.facebook.com/bablorub   \n",
       "1       fb  https://www.facebook.com/bablorub   \n",
       "2       fb  https://www.facebook.com/bablorub   \n",
       "3       fb  https://www.facebook.com/bablorub   \n",
       "4       fb  https://www.facebook.com/bablorub   \n",
       "\n",
       "                                      Ссылка на пост  \\\n",
       "0  https://www.facebook.com/bablorub/posts/368965...   \n",
       "1  https://www.facebook.com/bablorub/posts/361902...   \n",
       "2  https://www.facebook.com/bablorub/posts/350016...   \n",
       "3  https://www.facebook.com/bablorub/posts/349914...   \n",
       "4  https://www.facebook.com/bablorub/posts/360052...   \n",
       "\n",
       "                                         Текст поста  \n",
       "0  Как выживает ресторанная индустрия.\\nДа никак....  \n",
       "1  Ивентер 2019: ты едешь на велосипеде, который ...  \n",
       "2  Что хорошего.\\r\\nАгентство май закончило с при...  \n",
       "3  Это просто огнище! Бизнес пинками загоняют в с...  \n",
       "4  Отложенный спрос работал только пару недель по...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = pd.read_csv(\"postdata_new.csv\").fillna(\"\") \n",
    "data2 = pd.read_csv(\"postdata_new2.csv\").fillna(\"\")\n",
    "data = pd.concat([data1, data2])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = data['Текст поста']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cc6cc169b8842c1b02d3ff32fc34bed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=369.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "norm_texts = [normalize_text(clean_text(text)) for text in tqdm(texts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'работать месяц семь магазин прислать всего три магазин один раз весь проверить что не придираться продажа худой закрытие два месяц не жаловаться тот похожий специально сейчас вбрасывать народ раскачивать работать надо не ще жаловаться'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_texts[97]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>tag</th>\n",
       "      <th>value</th>\n",
       "      <th>pstv</th>\n",
       "      <th>neut</th>\n",
       "      <th>ngtv</th>\n",
       "      <th>dunno</th>\n",
       "      <th>distortion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>аббат</td>\n",
       "      <td>NEUT</td>\n",
       "      <td>0.3667</td>\n",
       "      <td>0.2574</td>\n",
       "      <td>0.3762</td>\n",
       "      <td>0.0693</td>\n",
       "      <td>0.2970</td>\n",
       "      <td>0.0880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>аббревиатура</td>\n",
       "      <td>NEUT</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>0.7200</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1200</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>абзац</td>\n",
       "      <td>NEUT</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1481</td>\n",
       "      <td>0.7037</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1481</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>абонемент</td>\n",
       "      <td>NEUT</td>\n",
       "      <td>0.1757</td>\n",
       "      <td>0.2381</td>\n",
       "      <td>0.5810</td>\n",
       "      <td>0.0476</td>\n",
       "      <td>0.1333</td>\n",
       "      <td>0.0571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>абонентный</td>\n",
       "      <td>NEUT</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.7200</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2800</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           term   tag   value    pstv    neut    ngtv   dunno  distortion\n",
       "0         аббат  NEUT  0.3667  0.2574  0.3762  0.0693  0.2970      0.0880\n",
       "1  аббревиатура  NEUT  0.0000  0.1600  0.7200  0.0000  0.1200      0.0000\n",
       "2         абзац  NEUT  0.0000  0.1481  0.7037  0.0000  0.1481      0.0000\n",
       "3     абонемент  NEUT  0.1757  0.2381  0.5810  0.0476  0.1333      0.0571\n",
       "4    абонентный  NEUT  0.0000  0.0000  0.7200  0.0000  0.2800      0.0000"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative = ['нестабильный', 'вышеднем', 'страшно', 'выгорание', 'тупо', 'демотивирован', 'закрываю', 'инфоцыган', 'сложно', 'кошмарят', 'банкротство' 'некомпетентности', 'игнорируются', 'нельзя', 'нервы', 'обязаловки', 'убыль', 'Позорище', 'коронакризис', 'скормил', 'против', 'экономить', 'херь']\n",
    "neutral = ['электрон', 'Видя', 'рекламщиками', 'штурм', 'вижу', 'вышло', 'подчиненные', 'долгожданное', 'дороже', 'кролик', 'коммуналку', 'Медузы', 'опять', 'отложенный', 'отмены', 'спишут', 'нужно', 'очередь', 'мелкими', 'подвести', 'душу', 'подчинении', 'чуваком', 'политики', 'пошли', 'разворачивание', 'топлю', 'рекламы', 'экология', 'следить', 'стихия', 'природа', 'Цепями','Учреждена']\n",
    "positive = ['успешно', 'идеально', 'добра', 'доделали', 'запуск', 'Запускаю', 'кайфе', 'легко', 'наконец', 'можно', 'открыть', 'продажи', 'прорвемся', 'удобно', 'ТОП', '']\n",
    "\n",
    "emo = pd.read_csv(\"emo_dict.csv\", sep=';')\n",
    "\n",
    "def genRow(term, kind):\n",
    "    if kind == 'NEUT':\n",
    "        values = {'tag':'NEUT', \n",
    "            'value':0.0, \n",
    "            'pstv':0.0000, \n",
    "            'neut':1.0, \n",
    "            'ngtv':0.0}\n",
    "        \n",
    "    elif kind == 'PSTV':\n",
    "        values = {'tag':'PSTV', \n",
    "            'value':1.0, \n",
    "            'pstv':1.0000, \n",
    "            'neut':0.0, \n",
    "            'ngtv':0.0}\n",
    "    else:\n",
    "        values = {'tag':'NGTV', \n",
    "            'value':-1.0, \n",
    "            'pstv':0.0000, \n",
    "            'neut':0.0, \n",
    "            'ngtv':-1.0}\n",
    "        \n",
    "    return {'term':term, \n",
    "            **values, \n",
    "            'dunno':0.000,\n",
    "            'distortion':0.0000}\n",
    "\n",
    "def add_word(df, word, kind):\n",
    "    word = morph.parse(word.lower())[0].normal_form\n",
    "    df = df.drop(df[df.term == word].index)\n",
    "    df = df.append(genRow(word, kind), ignore_index = True)\n",
    "    return df\n",
    "\n",
    "for neg in negative:\n",
    "    emo = add_word(emo, neg, 'NGTV')\n",
    "\n",
    "for neg in negative:\n",
    "    assert(len(emo[emo.term == neg]) > 0)\n",
    "        \n",
    "emo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "for text in norm_texts:\n",
    "    words.extend(text.split())\n",
    "words = list(set(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7109"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = []\n",
    "for word in words:\n",
    "    word_vectors.append(_word2vec(word))\n",
    "word_vectors = np.array(word_vectors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('разумный', 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[0], len(word_vectors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "emo_terms, emo_values = emo.term.values, emo.value.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "emo_dict = {}\n",
    "emo_vectors = []\n",
    "for i in range(len(emo_terms)):\n",
    "    emo_dict[emo_terms[i]] = emo_values[i]\n",
    "    emo_vectors.append(_word2vec(emo_terms[i]))\n",
    "emo_vectors = np.array(emo_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7109, 300), (28199, 300))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.shape, emo_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# матрица косинусных расстояний\n",
    "cos = cosine_similarity(word_vectors, emo_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7109, 28199)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 21114\n"
     ]
    }
   ],
   "source": [
    "for index in range(len(words)):\n",
    "    if words[index] in emo_terms:\n",
    "        print(index, np.where(emo_terms==words[index])[0][0])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#отношение слово из постов - слово из словаря\n",
    "word_connection = []\n",
    "for word_ind in range(len(words)):\n",
    "    word_connection.append(np.argmax(cos[word_ind]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "слово из поста; слово из словаря; cos; тональность\n",
      "разумный; разумный; 1.0; 1.0\n",
      "решение; решение; 0.9999999; 0.5308\n",
      "накладный; дорогостоящий; 0.4642231; -0.1369\n",
      "карман; карман; 0.9999999; 0.0\n",
      "взбучка; взбучка; 0.9999999; -1.0\n",
      "футбольный; футбольный; 1.0; 0.0\n",
      "кой; надобный; 0.6138623; 0.5263\n",
      "простой; простой; 0.99999976; 0.0\n",
      "обратно; сворачивать; 0.41277125; 0.0\n",
      "прецедент; факт; 0.46223208; 0.2179\n"
     ]
    }
   ],
   "source": [
    "print(\"слово из поста; слово из словаря; cos; тональность\")\n",
    "for i in range(len(word_connection[:10])):\n",
    "    print(words[i], emo_terms[word_connection[i]], cos[i][word_connection[i]], emo_dict[emo_terms[word_connection[i]]], sep='; ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_emos = dict()\n",
    "for i in range(len(word_connection)):\n",
    "    if cos[i][word_connection[i]] < 0.7:\n",
    "        words_emos[words[i]] = 0\n",
    "    else:\n",
    "        value = emo_dict[emo_terms[word_connection[i]]]\n",
    "        if value <= 0.65 and value > 0:\n",
    "            value = 0\n",
    "        elif value < 0:\n",
    "            value -= (value+1)/2\n",
    "        words_emos[words[i]] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'26.84%'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt = 0\n",
    "for word in words_emos:\n",
    "    if words_emos[word] != 0:\n",
    "        cnt += 1\n",
    "f\"{round(cnt / len(words_emos) * 100, 2)}%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_texts_values = []\n",
    "for text in norm_texts:\n",
    "    value = 0\n",
    "    cnt = 0\n",
    "    prevNot = 1\n",
    "    for word in text.split():\n",
    "        if words_emos[word] != 0:\n",
    "            cnt+=1\n",
    "            value += words_emos[word] * prevNot\n",
    "            \n",
    "        prevNot = 1\n",
    "        \n",
    "        if word == 'не':\n",
    "            prevNot = -1\n",
    "            \n",
    "    norm_texts_values.append(value / cnt if cnt > 0 else 0)\n",
    "norm_texts_values = np.array(norm_texts_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27724338220297096"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_texts_values.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_color(c):\n",
    "    if c >= 0:\n",
    "        return '#%02x%02x%02x' % (0, int(c * 255), 0)\n",
    "    else:\n",
    "        return '#%02x%02x%02x' % (int(-c * 255), 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a32f0577d6d46a8b0501190c1d3e9ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=369.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "color_texts = []\n",
    "for text in tqdm(texts):\n",
    "    fixed_text = text.replace('\\n', '\\n ')\n",
    "    col_t = []\n",
    "    prevNot = 1\n",
    "    for i, word in enumerate(fixed_text.split(\" \")):\n",
    "        lower_word = clean_text(word)\n",
    "        if len(word) == 0:\n",
    "            continue\n",
    "\n",
    "        if lower_word in words_norm_dict and words_norm_dict[lower_word]:\n",
    "            if prevNot == -1:\n",
    "                col_t[-2] = words_emos[words_norm_dict[lower_word]] * prevNot\n",
    "                    \n",
    "            col_t.append(words_emos[words_norm_dict[lower_word]] * prevNot)\n",
    "            prevNot = 1\n",
    "        else:\n",
    "            col_t.append(0)\n",
    "        if word == 'не':\n",
    "            prevNot = -1\n",
    "            \n",
    "        col_t.append(f\"{word} \")\n",
    "    color_texts.append(col_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'ans7.xlsx'\n",
    "workbook = xlsxwriter.Workbook(name)\n",
    "worksheet = workbook.add_worksheet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6fd6ca94d234e5f83cafb0d134177ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=369.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "scr_links = data['Ссылка на источник'].values\n",
    "post_links = data['Ссылка на пост'].values\n",
    "\n",
    "worksheet.write(0, 0, 'Ссылка на источник')\n",
    "worksheet.write(0, 1, 'Ссылка на пост')\n",
    "worksheet.write(0, 2, 'Текст поста')\n",
    "worksheet.write(0, 3, 'Коэффициент поста')\n",
    "\n",
    "for i, text in tqdm(enumerate(color_texts), total=len(color_texts)):\n",
    "    \n",
    "    index = i+1\n",
    "    \n",
    "    worksheet.write(index, 0, scr_links[i])\n",
    "    worksheet.write(index, 1, post_links[i])\n",
    "        \n",
    "    if len(text):\n",
    "        text_fmt = [workbook.add_format({'color': get_color(i)}) if type(i) in [int, np.float64] else i for i in text]\n",
    "        res = worksheet.write_rich_string(f'C{index+1}',*text_fmt)\n",
    "        if res != 0:\n",
    "            print(i, res)\n",
    "    \n",
    "    worksheet.write(index, 3, norm_texts_values[i])\n",
    "    \n",
    "worksheet.write(1, 4, 'Итоговый коэффициент')          \n",
    "worksheet.write_formula(f'F2', f'=AVERAGE(D1:D{len(texts)})')\n",
    "workbook.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1719 22541 1.0000001\n"
     ]
    }
   ],
   "source": [
    "index = words.index('свой')\n",
    "print(index, cos[index].argmax(), cos[index][cos[index].argmax()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('свой', 0.5476)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emo_terms[22541], emo_values[22541]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.134"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emo_dict['электрон']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'электрон'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "morph.parse('электрон')[0].normal_form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info(word):\n",
    "    word = morph.parse(word)[0].normal_form\n",
    "    print(\"Слово\", word)\n",
    "    word_index = words.index(word)\n",
    "    emo_index = word_connection[word_index]\n",
    "    print(\"Ближайшее\", emo_terms[emo_index], emo_dict[emo_terms[emo_index]])\n",
    "    print(\"РАсстояние:\", cos[word_index][emo_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Слово учредить\n",
      "Ближайшее учредить 0.1\n",
      "РАсстояние: 0.99999976\n"
     ]
    }
   ],
   "source": [
    "get_info('Учреждена')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'беременность' in emo_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>tag</th>\n",
       "      <th>value</th>\n",
       "      <th>pstv</th>\n",
       "      <th>neut</th>\n",
       "      <th>ngtv</th>\n",
       "      <th>dunno</th>\n",
       "      <th>distortion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>909</th>\n",
       "      <td>беременность</td>\n",
       "      <td>PSTV</td>\n",
       "      <td>0.657</td>\n",
       "      <td>0.5146</td>\n",
       "      <td>0.3301</td>\n",
       "      <td>0.1262</td>\n",
       "      <td>0.0291</td>\n",
       "      <td>0.1572</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             term   tag  value    pstv    neut    ngtv   dunno  distortion\n",
       "909  беременность  PSTV  0.657  0.5146  0.3301  0.1262  0.0291      0.1572"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emo[emo.term == 'беременность']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Частотность"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_cnt = Counter()\n",
    "for text in norm_texts:\n",
    "    for word in text.split():\n",
    "        if words_emos[word]:\n",
    "            words_cnt[word] += 1\n",
    "to_frec = []\n",
    "for word in words_cnt.most_common():\n",
    "    to_frec.append([word[0], word[1], words_emos[word[0]], 'положительное' if words_emos[word[0]] > 0 else 'отрицательное'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Слово</th>\n",
       "      <th>Кол-во употреблений</th>\n",
       "      <th>Коэффициент</th>\n",
       "      <th>Тональность</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>налог</td>\n",
       "      <td>196</td>\n",
       "      <td>-0.71295</td>\n",
       "      <td>отрицательное</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>хороший</td>\n",
       "      <td>138</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>положительное</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>нужный</td>\n",
       "      <td>138</td>\n",
       "      <td>0.98280</td>\n",
       "      <td>положительное</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>знать</td>\n",
       "      <td>109</td>\n",
       "      <td>0.69050</td>\n",
       "      <td>положительное</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>жизнь</td>\n",
       "      <td>95</td>\n",
       "      <td>0.80920</td>\n",
       "      <td>положительное</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Слово  Кол-во употреблений  Коэффициент    Тональность\n",
       "0    налог                  196     -0.71295  отрицательное\n",
       "1  хороший                  138      1.00000  положительное\n",
       "2   нужный                  138      0.98280  положительное\n",
       "3    знать                  109      0.69050  положительное\n",
       "4    жизнь                   95      0.80920  положительное"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_data = pd.DataFrame(to_frec, columns=['Слово', 'Кол-во употреблений', 'Коэффициент', 'Тональность'])\n",
    "freq_data.to_csv('words_freq.csv', decimal=',')\n",
    "freq_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8443"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([i[1] for i in words_cnt.most_common()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
