{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pck\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import *\n",
    "from dateutil.parser import parse\n",
    "from multiprocessing import Pool\n",
    "from multiprocessing.dummy import Pool as DPool\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from openpyxl.styles import PatternFill, Border, Side, Alignment, Protection, Font\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import swifter\n",
    "import matplotlib as mpl\n",
    "import matplotlib.backends.backend_pdf\n",
    "import re\n",
    "from numba import jit\n",
    "import pymorphy2\n",
    "import math\n",
    "import gensim\n",
    "from typing import List, Tuple\n",
    "import openpyxl\n",
    "from googletrans import Translator\n",
    "import time\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "import plotly.express as px\n",
    "from datetime import *\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import plotly.io as pi\n",
    "\n",
    "pio.orca.config.use_xvfb = True\n",
    "pio.orca.config.use_xvfb = False\n",
    "mpl.rc(\"savefig\", dpi=200)\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "translator = Translator()\n",
    "\n",
    "pd.options.display.max_columns = 500\n",
    "pd.options.display.max_rows = 300\n",
    "\n",
    "import xlsxwriter\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>tag</th>\n",
       "      <th>value</th>\n",
       "      <th>pstv</th>\n",
       "      <th>neut</th>\n",
       "      <th>ngtv</th>\n",
       "      <th>dunno</th>\n",
       "      <th>distortion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>аббат</td>\n",
       "      <td>NEUT</td>\n",
       "      <td>0.3667</td>\n",
       "      <td>0.2574</td>\n",
       "      <td>0.3762</td>\n",
       "      <td>0.0693</td>\n",
       "      <td>0.2970</td>\n",
       "      <td>0.0880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>аббревиатура</td>\n",
       "      <td>NEUT</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>0.7200</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1200</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>абзац</td>\n",
       "      <td>NEUT</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1481</td>\n",
       "      <td>0.7037</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1481</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>абонемент</td>\n",
       "      <td>NEUT</td>\n",
       "      <td>0.1757</td>\n",
       "      <td>0.2381</td>\n",
       "      <td>0.5810</td>\n",
       "      <td>0.0476</td>\n",
       "      <td>0.1333</td>\n",
       "      <td>0.0571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>абонентный</td>\n",
       "      <td>NEUT</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.7200</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2800</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           term   tag   value    pstv    neut    ngtv   dunno  distortion\n",
       "0         аббат  NEUT  0.3667  0.2574  0.3762  0.0693  0.2970      0.0880\n",
       "1  аббревиатура  NEUT  0.0000  0.1600  0.7200  0.0000  0.1200      0.0000\n",
       "2         абзац  NEUT  0.0000  0.1481  0.7037  0.0000  0.1481      0.0000\n",
       "3     абонемент  NEUT  0.1757  0.2381  0.5810  0.0476  0.1333      0.0571\n",
       "4    абонентный  NEUT  0.0000  0.0000  0.7200  0.0000  0.2800      0.0000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_vector = np.array([0] * 300, dtype=np.float32)\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('../hh_data/model.bin', binary=True)\n",
    "def _word2vec(word):\n",
    "    for i in [\"_NOUN\", \"_ADJ\", \"_VERB\"]:\n",
    "        tmp = \"{}{}\".format(word, i)\n",
    "        if tmp in model:\n",
    "            return model[tmp]\n",
    "\n",
    "    return np.array(tmp_vector)\n",
    "\n",
    "def normalize_word(word):\n",
    "    norm_words = morph.parse(word)\n",
    "    \n",
    "    res = None\n",
    "    \n",
    "    for norm_word in norm_words:\n",
    "        # Если слово не предлог и не союз\n",
    "        # Не в стоп словах и длинна слова больше одного символа\n",
    "        if word in ['не', 'нет', 'без'] or norm_word.tag.POS not in ['PREP', 'CONJ', 'PRCL', 'INTJ'] \\\n",
    "            and norm_word.normal_form and len(norm_word.normal_form) > 1 and norm_word.score > 0.1 \\\n",
    "            and (np.linalg.norm(_word2vec(norm_word.normal_form)) > 0 or norm_word.normal_form in neutral + positive + negative):\n",
    "\n",
    "            # Сохраним первую форму слова\n",
    "            res = norm_word.normal_form\n",
    "            break\n",
    "    return morph.parse(word.lower())[0].normal_form\n",
    "\n",
    "\n",
    "negative = ['нестабильный', 'вышеднем', 'коронабесные', 'коронаканикулы', 'страшно', 'выгорание', 'тупо', 'демотивирован', 'закрываю', 'инфоцыган', 'сложно', 'кошмарят', 'банкротства', 'банкротству', 'некомпетентности', 'некомпетентностью', 'игнорируются', 'нельзя', 'нервы', 'обязаловки', 'убыль', 'Позорище', 'коронакризис', 'скормил', 'против', 'экономить', 'херь']\n",
    "neutral = ['электрон', 'мире', 'Видя', 'рекламщиками', 'штурм', 'вижу', 'вышло', 'подчиненные', 'долгожданное', 'дороже', 'кролик', 'коммуналку', 'Медузы', 'опять', 'отложенный', 'отмены', 'спишут', 'нужно', 'очередь', 'мелкими', 'подвести', 'душу', 'подчинении', 'чуваком', 'политики', 'пошли', 'разворачивание', 'топлю', 'рекламы', 'экология', 'следить', 'стихия', 'природа', 'Цепями']\n",
    "positive = ['успешно', 'идеально', 'добра', 'доделали', 'запуск', 'Запускаю', 'кайфе', 'легко', 'наконец', 'можно', 'открыть', 'продажи', 'прорвёмся', 'удобно', 'ТОП', 'Учреждена', 'возобновил', 'открыты']\n",
    "\n",
    "negative = [normalize_word(word) for word in negative]\n",
    "neutral = [normalize_word(word) for word in neutral]\n",
    "positive = [normalize_word(word) for word in positive]\n",
    "\n",
    "emo = pd.read_csv(\"emo_dict.csv\", sep=';')\n",
    "\n",
    "\n",
    "def genRow(term, kind):\n",
    "    if kind == 'NEUT':\n",
    "        values = {'tag':'NEUT', \n",
    "            'value':0.0, \n",
    "            'pstv':0.0000, \n",
    "            'neut':1.0, \n",
    "            'ngtv':0.0}\n",
    "        \n",
    "    elif kind == 'PSTV':\n",
    "        values = {'tag':'PSTV', \n",
    "            'value':1.0, \n",
    "            'pstv':1.0000, \n",
    "            'neut':0.0, \n",
    "            'ngtv':0.0}\n",
    "    else:\n",
    "        values = {'tag':'NGTV', \n",
    "            'value':-1.0, \n",
    "            'pstv':0.0000, \n",
    "            'neut':0.0, \n",
    "            'ngtv':-1.0}\n",
    "        \n",
    "    return {'term':term, \n",
    "            **values, \n",
    "            'dunno':0.000,\n",
    "            'distortion':0.0000}\n",
    "\n",
    "def add_word(df, word, kind):\n",
    "    df = df.drop(df[df.term == word].index)\n",
    "    df = df.append(genRow(word, kind), ignore_index = True)\n",
    "    return df\n",
    "\n",
    "for neg in negative:\n",
    "    emo = add_word(emo, neg, 'NGTV')\n",
    "    assert(len(emo[emo.term == neg]) == 1 and emo[emo.term == neg].value.values[0] == -1)\n",
    "    \n",
    "for neut in neutral:\n",
    "    emo = add_word(emo, neut, 'NEUT')\n",
    "    assert(len(emo[emo.term == neut]) == 1 and emo[emo.term == neut].value.values[0] == 0)\n",
    "\n",
    "for pstv in positive:\n",
    "    emo = add_word(emo, pstv, 'PSTV')\n",
    "    assert(len(emo[emo.term == pstv]) == 1 and emo[emo.term == pstv].value.values[0] == 1)\n",
    "        \n",
    "emo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>tag</th>\n",
       "      <th>value</th>\n",
       "      <th>pstv</th>\n",
       "      <th>neut</th>\n",
       "      <th>ngtv</th>\n",
       "      <th>dunno</th>\n",
       "      <th>distortion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6602</th>\n",
       "      <td>зарплата</td>\n",
       "      <td>NGTV</td>\n",
       "      <td>-0.900</td>\n",
       "      <td>0.0294</td>\n",
       "      <td>0.2353</td>\n",
       "      <td>0.7059</td>\n",
       "      <td>0.0294</td>\n",
       "      <td>0.0306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7914</th>\n",
       "      <td>каникулы</td>\n",
       "      <td>PSTV</td>\n",
       "      <td>0.651</td>\n",
       "      <td>0.8621</td>\n",
       "      <td>0.1034</td>\n",
       "      <td>0.0345</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0359</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          term   tag  value    pstv    neut    ngtv   dunno  distortion\n",
       "6602  зарплата  NGTV -0.900  0.0294  0.2353  0.7059  0.0294      0.0306\n",
       "7914  каникулы  PSTV  0.651  0.8621  0.1034  0.0345  0.0000      0.0359"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value = float(emo[emo.term == 'зарплата'].value.values[0])\n",
    "emo.loc[emo.term == 'зарплата', 'value'] = -0.9\n",
    "emo.loc[emo.term == 'зарплата', 'tag'] = 'NGTV'\n",
    "emo.loc[emo.term == 'зарплата', 'pstv'] = 0.0294\n",
    "emo.loc[emo.term == 'зарплата', 'ngtv'] = 0.7059\n",
    "\n",
    "value = float(emo[emo.term == 'каникулы'].value.values[0])\n",
    "emo.loc[emo.term == 'каникулы', 'value'] = 0.651\n",
    "\n",
    "emo[(emo.term == 'зарплата') | (emo.term == 'каникулы')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_norm_dict = {}\n",
    "\n",
    "def clean_text(name):\n",
    "    '''Первичная очистка названия вакансии'''\n",
    "    \n",
    "    # Приведем к нижнему регистру\n",
    "    name = name.lower().replace('...', ' ').replace(\"ё\", 'е')\n",
    "    \n",
    "    # Оставим только буквы\n",
    "    name = re.sub(r\"[^a-zа-я]+\", ' ', name).strip()\n",
    "    \n",
    "    return name\n",
    "\n",
    "def normalize_text(name):\n",
    "    \n",
    "    normal_name = \"\"\n",
    "    name = name.replace(\"\\n\", \" \")\n",
    "    # Для каждого слова в вакансии\n",
    "    for word in name.split():\n",
    "        \n",
    "        found_norm_word = None\n",
    "        \n",
    "        # Если слово не в кэше\n",
    "        if word not in words_norm_dict.keys():\n",
    "            # Распарсим его\n",
    "            found_norm_word = normalize_word(word)\n",
    "                    \n",
    "            # Запишем слово в кэш\n",
    "            words_norm_dict[word] = found_norm_word\n",
    "        else:\n",
    "            # Если слово находится в кэше - просто достанем результат\n",
    "            found_norm_word = words_norm_dict[word]\n",
    "\n",
    "        # Если результат не отрицательный и слово есть\n",
    "        if found_norm_word:\n",
    "            # Запишим его в нормализованную вакнасию\n",
    "            normal_name = f\"{normal_name} {found_norm_word}\"\n",
    "            \n",
    "    normal_name = normal_name.strip()\n",
    "    return normal_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ссылка на источник</th>\n",
       "      <th>Ссылка на пост</th>\n",
       "      <th>Текст поста</th>\n",
       "      <th>Коэффициент поста</th>\n",
       "      <th>Тема 1</th>\n",
       "      <th>Тема 2</th>\n",
       "      <th>Тема 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.facebook.com/bablorub</td>\n",
       "      <td>https://www.facebook.com/bablorub/posts/368965...</td>\n",
       "      <td>Как выживает ресторанная индустрия.\\nДа никак....</td>\n",
       "      <td></td>\n",
       "      <td>Бизнес справился с кризисом</td>\n",
       "      <td>Нехватка средств / закрытие бизнеса</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.facebook.com/bablorub</td>\n",
       "      <td>https://www.facebook.com/bablorub/posts/361902...</td>\n",
       "      <td>Ивентер 2019: ты едешь на велосипеде, который ...</td>\n",
       "      <td></td>\n",
       "      <td>Неопределенность, страх, выгорание из-за пандемии</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.facebook.com/bablorub</td>\n",
       "      <td>https://www.facebook.com/bablorub/posts/360052...</td>\n",
       "      <td>Отложенный спрос работал только пару недель по...</td>\n",
       "      <td></td>\n",
       "      <td>Снижение потребительского спроса</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.facebook.com/bablorub</td>\n",
       "      <td>https://www.facebook.com/bablorub/posts/359459...</td>\n",
       "      <td>На глазах рождается новый анекдот.\\n- Деда, а ...</td>\n",
       "      <td></td>\n",
       "      <td>Нехватка средств / закрытие бизнеса</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.facebook.com/bablorub</td>\n",
       "      <td>https://www.facebook.com/bablorub/posts/357796...</td>\n",
       "      <td>Что произошло с Васей и Петей и их бизнесами? ...</td>\n",
       "      <td></td>\n",
       "      <td>Снижение потребительского спроса</td>\n",
       "      <td>Необходимость адаптироваться под новые условия</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Ссылка на источник  \\\n",
       "0  https://www.facebook.com/bablorub   \n",
       "1  https://www.facebook.com/bablorub   \n",
       "2  https://www.facebook.com/bablorub   \n",
       "3  https://www.facebook.com/bablorub   \n",
       "4  https://www.facebook.com/bablorub   \n",
       "\n",
       "                                      Ссылка на пост  \\\n",
       "0  https://www.facebook.com/bablorub/posts/368965...   \n",
       "1  https://www.facebook.com/bablorub/posts/361902...   \n",
       "2  https://www.facebook.com/bablorub/posts/360052...   \n",
       "3  https://www.facebook.com/bablorub/posts/359459...   \n",
       "4  https://www.facebook.com/bablorub/posts/357796...   \n",
       "\n",
       "                                         Текст поста Коэффициент поста  \\\n",
       "0  Как выживает ресторанная индустрия.\\nДа никак....                     \n",
       "1  Ивентер 2019: ты едешь на велосипеде, который ...                     \n",
       "2  Отложенный спрос работал только пару недель по...                     \n",
       "3  На глазах рождается новый анекдот.\\n- Деда, а ...                     \n",
       "4  Что произошло с Васей и Петей и их бизнесами? ...                     \n",
       "\n",
       "                                              Тема 1  \\\n",
       "0                        Бизнес справился с кризисом   \n",
       "1  Неопределенность, страх, выгорание из-за пандемии   \n",
       "2                   Снижение потребительского спроса   \n",
       "3                Нехватка средств / закрытие бизнеса   \n",
       "4                   Снижение потребительского спроса   \n",
       "\n",
       "                                           Тема 2 Тема 3  \n",
       "0             Нехватка средств / закрытие бизнеса         \n",
       "1                                                         \n",
       "2                                                         \n",
       "3                                                         \n",
       "4  Необходимость адаптироваться под новые условия         "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = pd.read_csv(\"posts_cv3.csv\").fillna(\"\") \n",
    "data = pd.concat([data1])\n",
    "print(len(data))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = data['Текст поста']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c9d6cc7679b43c684f17ea954036a85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=400.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "norm_texts = [normalize_text(clean_text(text)) for text in tqdm(texts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "for text in norm_texts:\n",
    "    words.extend(text.split())\n",
    "words = list(set(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9530"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = []\n",
    "for word in words:\n",
    "    word_vectors.append(_word2vec(word))\n",
    "word_vectors = np.array(word_vectors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('разницой', 300)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[0], len(word_vectors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "emo_terms, emo_values = emo.term.values, emo.value.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "emo_dict = {}\n",
    "emo_vectors = []\n",
    "for i in range(len(emo_terms)):\n",
    "    emo_dict[emo_terms[i]] = emo_values[i]\n",
    "    emo_vectors.append(_word2vec(emo_terms[i]))\n",
    "emo_vectors = np.array(emo_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9530, 300), (28223, 300))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.shape, emo_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# матрица косинусных расстояний\n",
    "cos = cosine_similarity(word_vectors, emo_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9530, 28223)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 27853\n"
     ]
    }
   ],
   "source": [
    "for index in range(len(words)):\n",
    "    if words[index] in emo_terms:\n",
    "        print(index, np.where(emo_terms==words[index])[0][0])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#отношение слово из постов - слово из словаря\n",
    "word_connection = []\n",
    "for word_ind in range(len(words)):\n",
    "    word_connection.append(np.argmax(cos[word_ind]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "слово из поста; слово из словаря; cos; тональность\n",
      "разницой; аббат; 0.0; 0.3667\n",
      "экологический; экологический; 0.99999976; 0.7925\n",
      "ндфл; аббат; 0.0; 0.3667\n",
      "medium; аббат; 0.0; 0.3667\n",
      "традиция; традиция; 1.0; 0.6364\n",
      "выкладка; рассуждение; 0.4888876; 0.5301\n",
      "кредиторский; кредиторский; 1.0000001; 0.0\n",
      "парковый; парковый; 1.0000001; 0.09300000000000001\n",
      "просить; просить; 0.9999999; 0.0893\n",
      "дата; дата; 0.99999976; 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"слово из поста; слово из словаря; cos; тональность\")\n",
    "for i in range(len(word_connection[:10])):\n",
    "    print(words[i], emo_terms[word_connection[i]], cos[i][word_connection[i]], emo_dict[emo_terms[word_connection[i]]], sep='; ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_emos = dict()\n",
    "for i in range(len(word_connection)):\n",
    "    if words[i] in emo_dict:\n",
    "        value = emo_dict[words[i]]\n",
    "        if value <= 0.65 and value > 0:\n",
    "            value = 0\n",
    "        elif value < 0:\n",
    "            value -= (value+1)/2\n",
    "        words_emos[words[i]] = value\n",
    "        continue\n",
    "        \n",
    "    if cos[i][word_connection[i]] < 0.7:\n",
    "        words_emos[words[i]] = 0\n",
    "    else:\n",
    "        value = emo_dict[emo_terms[word_connection[i]]]\n",
    "        if value <= 0.651 and value > 0:\n",
    "            value = 0\n",
    "        elif value < 0:\n",
    "            value -= (value+1)/2\n",
    "        words_emos[words[i]] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20.89%'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt = 0\n",
    "for word in words_emos:\n",
    "    if words_emos[word] != 0:\n",
    "        cnt += 1\n",
    "f\"{round(cnt / len(words_emos) * 100, 2)}%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_emos[words_norm_dict['позорище']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_texts_values = []\n",
    "for text in norm_texts:\n",
    "    value = 0\n",
    "    cnt = 0\n",
    "    prevNot = 1\n",
    "    for word in text.split():\n",
    "        if words_emos[word] != 0:\n",
    "            cnt+=1\n",
    "            value += words_emos[word] * prevNot\n",
    "            \n",
    "        prevNot = 1\n",
    "        \n",
    "        if word == 'не':\n",
    "            prevNot = -1\n",
    "            \n",
    "    norm_texts_values.append(value / cnt if cnt > 0 else 0)\n",
    "norm_texts_values = np.array(norm_texts_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3628703701370506"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_texts_values.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_color(c):\n",
    "    if c >= 0:\n",
    "        return '#%02x%02x%02x' % (0, int(c * 255), 0)\n",
    "    else:\n",
    "        return '#%02x%02x%02x' % (int(-c * 255), 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f9c566a2e7d435fa7435258b01a485f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=400.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "color_texts = []\n",
    "for text in tqdm(texts):\n",
    "    fixed_text = text.replace('\\n', '\\n ').replace(\".\", '. ')\n",
    "    col_t = []\n",
    "    prevNot = 1\n",
    "    for i, word in enumerate(fixed_text.split(\" \")):\n",
    "        lower_word = clean_text(word).split(' ')[0]\n",
    "        if len(word) == 0:\n",
    "            continue\n",
    "        \n",
    "        if lower_word in words_norm_dict and words_norm_dict[lower_word]:\n",
    "            if prevNot == -1:\n",
    "                col_t[-2] = words_emos[words_norm_dict[lower_word]] * prevNot\n",
    "                    \n",
    "            col_t.append(words_emos[words_norm_dict[lower_word]] * prevNot)\n",
    "        else:\n",
    "            col_t.append(0)\n",
    "        prevNot = 1\n",
    "        \n",
    "        if word.lower() in ['не', 'нет', 'без']:\n",
    "            prevNot = -1\n",
    "            \n",
    "        col_t.append(f\"{word} \")\n",
    "    color_texts.append(col_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.651"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_emos[words_norm_dict['каникулы']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = '/mnt/Modulebank/ans.xlsx'\n",
    "workbook = xlsxwriter.Workbook(name)\n",
    "worksheet = workbook.add_worksheet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9395c26554d4aa3b962dd51127a688b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=400.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "scr_links = data['Ссылка на источник'].values\n",
    "post_links = data['Ссылка на пост'].values\n",
    "\n",
    "worksheet.write(0, 0, 'Ссылка на источник')\n",
    "worksheet.write(0, 1, 'Ссылка на пост')\n",
    "worksheet.write(0, 2, 'Текст поста')\n",
    "worksheet.write(0, 3, 'Коэффициент поста')\n",
    "\n",
    "for i, text in tqdm(enumerate(color_texts), total=len(color_texts)):\n",
    "    \n",
    "    index = i+1\n",
    "    \n",
    "    worksheet.write(index, 0, scr_links[i])\n",
    "    worksheet.write(index, 1, post_links[i])\n",
    "        \n",
    "    if len(text):\n",
    "        text_fmt = [workbook.add_format({'color': get_color(i)}) if type(i) in [int, np.float64] else i for i in text]\n",
    "        res = worksheet.write_rich_string(f'C{index+1}',*text_fmt)\n",
    "        if res != 0:\n",
    "            print(i, res)\n",
    "    \n",
    "    worksheet.write(index, 3, norm_texts_values[i])\n",
    "    \n",
    "worksheet.write(1, 4, 'Итоговый коэффициент')          \n",
    "worksheet.write_formula(f'F2', f'=AVERAGE(D1:D{len(texts)})')\n",
    "workbook.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9137 22503 1.0000001\n"
     ]
    }
   ],
   "source": [
    "index = words.index('свой')\n",
    "print(index, cos[index].argmax(), cos[index][cos[index].argmax()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('сглаживать', 0.732)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emo_terms[22541], emo_values[22541]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_emos['добро']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'электрон'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "morph.parse('электрон')[0].normal_form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info(word):\n",
    "    word = morph.parse(word)[0].normal_form\n",
    "    print(\"Слово\", word)\n",
    "    word_index = words.index(word)\n",
    "    emo_index = word_connection[word_index]\n",
    "    print(\"Ближайшее\", emo_terms[emo_index], emo_dict[emo_terms[emo_index]])\n",
    "    print(\"РАсстояние:\", cos[word_index][emo_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Слово добро\n",
      "Ближайшее добро 1.0\n",
      "РАсстояние: 1.0000002\n"
     ]
    }
   ],
   "source": [
    "get_info('добро')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'беременность' in emo_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>tag</th>\n",
       "      <th>value</th>\n",
       "      <th>pstv</th>\n",
       "      <th>neut</th>\n",
       "      <th>ngtv</th>\n",
       "      <th>dunno</th>\n",
       "      <th>distortion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>909</th>\n",
       "      <td>беременность</td>\n",
       "      <td>PSTV</td>\n",
       "      <td>0.657</td>\n",
       "      <td>0.5146</td>\n",
       "      <td>0.3301</td>\n",
       "      <td>0.1262</td>\n",
       "      <td>0.0291</td>\n",
       "      <td>0.1572</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             term   tag  value    pstv    neut    ngtv   dunno  distortion\n",
       "909  беременность  PSTV  0.657  0.5146  0.3301  0.1262  0.0291      0.1572"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emo[emo.term == 'беременность']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Частотность"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_cnt = Counter()\n",
    "for text in norm_texts:\n",
    "    for word in text.split():\n",
    "        if words_emos[word]:\n",
    "            words_cnt[word] += 1\n",
    "to_frec = []\n",
    "for word in words_cnt.most_common():\n",
    "    to_frec.append([word[0], word[1], words_emos[word[0]], 'положительное' if words_emos[word[0]] > 0 else 'отрицательное'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Слово</th>\n",
       "      <th>Кол-во употреблений</th>\n",
       "      <th>Коэффициент</th>\n",
       "      <th>Тональность</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>налог</td>\n",
       "      <td>148</td>\n",
       "      <td>-0.71295</td>\n",
       "      <td>отрицательное</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>хороший</td>\n",
       "      <td>144</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>положительное</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>можно</td>\n",
       "      <td>132</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>положительное</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>жизнь</td>\n",
       "      <td>93</td>\n",
       "      <td>0.80920</td>\n",
       "      <td>положительное</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>знать</td>\n",
       "      <td>81</td>\n",
       "      <td>0.69050</td>\n",
       "      <td>положительное</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Слово  Кол-во употреблений  Коэффициент    Тональность\n",
       "0    налог                  148     -0.71295  отрицательное\n",
       "1  хороший                  144      1.00000  положительное\n",
       "2    можно                  132      1.00000  положительное\n",
       "3    жизнь                   93      0.80920  положительное\n",
       "4    знать                   81      0.69050  положительное"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_data = pd.DataFrame(to_frec, columns=['Слово', 'Кол-во употреблений', 'Коэффициент', 'Тональность'])\n",
    "freq_data.to_csv('words_freq.csv', decimal=',')\n",
    "freq_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8355"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([i[1] for i in words_cnt.most_common()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
